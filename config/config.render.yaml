# Render.com deployment configuration

database:
  url: ${DATABASE_URL}  # Automatically set by Render

models:
  models:
  embedding:
    model_name: sentence-transformers/all-MiniLM-L6-v2
    cache_dir: /opt/render/.cache/huggingface
    device: cpu
    batch_size: 4  # Reduced from 8
  
  reranker:
    model_name: cross-encoder/ms-marco-MiniLM-L-6-v2
    cache_dir: /opt/render/.cache/huggingface
    device: cpu
    batch_size: 4  # Reduced from 8
  
  llm:
    provider: groq
    model: llama-3.1-70b-versatile
    temperature: 0.1
    max_tokens: 1000
    base_url: null
  
  vision:
    provider: groq
    model: llama-3.2-90b-vision-preview
    base_url: null

search:
  hybrid:
    vector_weight: 0.7
    keyword_weight: 0.3
    top_k_candidates: 50
  
  rerank:
    top_k: 10
  
  evidence:
    min_score: 0.65
    insufficient_threshold: 2
    medium_threshold: 3
    high_threshold: 5
    max_sources: 8

ingestion:
  git:
    url: null
    branch: main
    local_path: /tmp/docs
  
  docs_base_url: null
  
  markdown:
    extract_code_blocks: true
    extract_images: true
  
  chunking:
    strategy: section
    max_tokens: 512

api:
  cors_origins:
    - "*"
  rate_limit_enabled: false
  rate_limit_requests_per_minute: 60

logging:
  level: INFO
  format: json
  file: null